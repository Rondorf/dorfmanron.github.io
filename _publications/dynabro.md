---
title: "Offline Meta Reinforcement Learning ‚Äì Identifiability Challenges and Effective Data Collection Strategies"
collection: publications
permalink: /publications/offlineMetaRL
excerpt: "Consider the following instance of the Offline Meta Reinforcement Learning (OMRL) problem: given the complete training logs of  conventional RL agents, trained on different tasks, design a meta-agent that can quickly maximize reward in a new, unseen task from the same task distribution. In particular, while each conventional RL agent explored and exploited its own different task, the meta-agent must identify regularities in the data that lead to effective exploration/exploitation in the unseen task. Here, we take a Bayesian RL (BRL) view, and seek to learn a Bayes-optimal policy from the offline data. Building on the recent VariBAD BRL approach, we develop an off-policy BRL method that learns to plan an exploration strategy based on an adaptive neural belief estimate. However, learning to infer such a belief from offline data brings a new identifiability issue we term MDP ambiguity. We characterize the problem, and suggest resolutions via data collection and modification procedures. Finally, we evaluate our framework on a diverse set of domains, including difficult sparse reward tasks, and demonstrate learning of effective exploration behavior that is qualitatively different from the exploration used by any RL agent in the data." 
venue: '35th Conference on Neural Information Processing Systems (NeurIPS)'
date: 2021-12-06
pdfurl: 'https://proceedings.neurips.cc/paper/2021/file/248024541dbda1d3fd75fe49d1a4df4d-Paper.pdf'
---  
Byzantine-robust learning has emerged as a prominent fault-tolerant distributed machine learning framework. However, most techniques consider the static setting, wherein the identity of Byzantine machines remains fixed during the learning process. This assumption does not capture real-world dynamic Byzantine behaviors, which may include transient malfunctions or targeted temporal attacks. Addressing this limitation, we propose ùñ£ùóíùóáùñ∫ùñ°ùñ±ùñÆ -- a new method capable of withstanding $\mathcal{O}(\sqrt{T})$ rounds of Byzantine identity alterations (where $T$ is the total number of training rounds), while matching the asymptotic convergence rate of the static setting. Our method combines a multi-level Monte Carlo (MLMC) gradient estimation technique with robust aggregation of worker updates and incorporates a fail-safe filter to limit bias from dynamic Byzantine strategies. Additionally, by leveraging an adaptive learning rate, our approach eliminates the need for knowing the percentage of Byzantine workers.  <br> <br> <a href='https://arxiv.org/abs/2402.02951'>link</a> <br> <br> 